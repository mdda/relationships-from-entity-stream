{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, d = 1024, 5  # d is size of input\n",
    "\n",
    "x_np = np.random.randint( d, size=(batch_size,1) )\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "t_long = torch.LongTensor\n",
    "t_float = torch.FloatTensor\n",
    "if use_cuda:\n",
    "    t_long = torch.cuda.LongTensor\n",
    "    t_float = torch.cuda.FloatTensor\n",
    "\n",
    "# Create Tensors to hold inputs and outputs, and wrap them in Variables\n",
    "x = Variable( torch.from_numpy(x_np).type( t_long ) )\n",
    "y = Variable( torch.from_numpy(x_np).type( t_long ).squeeze(), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectorNet(torch.nn.Module):\n",
    "  def __init__(self, D):\n",
    "    \"\"\"\n",
    "    In the constructor we instantiate nn modules and assign them as member variables.\n",
    "    \"\"\"\n",
    "    super(SelectorNet, self).__init__()\n",
    "    \n",
    "    self.input_space = torch.FloatTensor(batch_size, D).type(t_float) \n",
    "    self.linear = torch.nn.Linear(D, D)  # The weights in here should become the identity\n",
    "\n",
    "  def forward(self, i):\n",
    "    \"\"\"\n",
    "    In the forward function we accept a Variable of input data and we must return\n",
    "    a Variable of output data. We can use Modules defined in the constructor as\n",
    "    well as arbitrary operators on Variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert the input 'i' into a one-hot vector\n",
    "    self.input_space.zero_()\n",
    "    self.input_space.scatter_(1, i.data, 1.)\n",
    "    #self.input_space.scatter_(1, Variable(i), 1.)\n",
    "    \n",
    "    x = Variable( self.input_space )\n",
    "    #print(x.size())\n",
    "    logits = self.linear(x)\n",
    "    #print(logits.size())\n",
    "    \n",
    "    #.clamp(min=0)\n",
    "    #y_pred = self.linear2(h_relu)\n",
    "    \n",
    "    #action1 = torch.nn.SoftMax(logits)\n",
    "    \n",
    "    action = logits\n",
    "    #y_probs, y_idx = torch.max(action1)\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct our model by instantiating the class defined above\n",
    "model = SelectorNet(d)\n",
    "if use_cuda: model = model.cuda()\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the nn modules \n",
    "# which are members of the model.\n",
    "\n",
    "#criterion = torch.nn.MSELoss(size_average=False)\n",
    "criterion = torch.nn.NLLLoss(size_average=True)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-4) # \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-1) # \n",
    "\n",
    "for t in range(100):\n",
    "  # Forward pass: Compute predicted y by passing x to the model\n",
    "  y_pred = model(x)\n",
    "\n",
    "  # Compute and print loss\n",
    "  loss = criterion(y_pred, y)\n",
    "  if (t+1) % 10 ==0 :\n",
    "      print(t+1, loss.data[0])\n",
    "\n",
    "  # Zero gradients, perform a backward pass, and update the weights.\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "print(model.linear.weight.data,)# model.linear.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
